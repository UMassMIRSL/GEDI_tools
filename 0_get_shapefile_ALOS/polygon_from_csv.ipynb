{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain a polygon shapefile corresponding to a given path and row of ALOS PALSAR 1 data. This can be be used for subsetting GEDI LIDAR data, which can be used as an input for the Forest Stand Height algorithm (https://github.com/leiyangleon/FSH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bookkeeping\n",
    "\n",
    "import fiona #to export shapefile easily\n",
    "from fiona.crs import from_epsg\n",
    "{'init': 'epsg:4326', 'no_defs': True}\n",
    "import pandas as pd #to read the ASF csv file having the path/row extents of ALOS1 scenes\n",
    "from shapely.geometry import mapping, Point, Polygon #to create the geomoetries\n",
    "import geopandas as gpd #facilitates geometry operations\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To obtain the ASF ALOS-1 scene information csv file\n",
    "1. Go to https://search.asf.alaska.edu/\n",
    "2. Set these settings:\n",
    "    1. Search type: Geographic\n",
    "    2. Dataset : ALOS PALSAR\n",
    "    3. Search Filters: Additional Filters: \n",
    "        1. File Type: Level 1.0\n",
    "        2. Beam Mode FBD\n",
    "    4. Search Filters: Path and Frame Filters:\n",
    "        1. Path Start: 142\n",
    "        2. Path End: 142\n",
    "        3. Frame Start: 40\n",
    "        4. Frame End: 40\n",
    "3. Add all results to downloads (icon just above the scene listing, cart with plus sign)\n",
    "4. Click on Cart in top right corner, next to Sign In\n",
    "5. Select Metadata Download, Metadata (csv)\n",
    "\n",
    "## The downloaded CSV file will be the input for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xx = pd.read_csv('asf-datapool-results-2020-06-04_02-37-17.csv')\n",
    "xx = pd.read_csv('asf-datapool-results-2020-06-24_12-42-55.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Granule Name',\n",
       " 'Platform',\n",
       " 'Sensor',\n",
       " 'Beam Mode',\n",
       " 'Beam Mode Description',\n",
       " 'Orbit',\n",
       " 'Path Number',\n",
       " 'Frame Number',\n",
       " 'Acquisition Date',\n",
       " 'Processing Date',\n",
       " 'Processing Level',\n",
       " 'Start Time',\n",
       " 'End Time',\n",
       " 'Center Lat',\n",
       " 'Center Lon',\n",
       " 'Near Start Lat',\n",
       " 'Near Start Lon',\n",
       " 'Far Start Lat',\n",
       " 'Far Start Lon',\n",
       " 'Near End Lat',\n",
       " 'Near End Lon',\n",
       " 'Far End Lat',\n",
       " 'Far End Lon',\n",
       " 'Faraday Rotation',\n",
       " 'Ascending or Descending?',\n",
       " 'URL',\n",
       " 'Size (MB)',\n",
       " 'Off Nadir Angle',\n",
       " 'Stack Size',\n",
       " 'Baseline Perp.',\n",
       " 'Doppler',\n",
       " 'GroupID']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the four corner points from the near/far start/end lon/lat values\n",
    "xx['p1'] = xx.apply(lambda row: Point(row['Near Start Lon'], row['Near Start Lat']), axis = 1)\n",
    "xx['p2'] = xx.apply(lambda row: Point(row['Far Start Lon'], row['Far Start Lat']), axis = 1)\n",
    "xx['p3'] = xx.apply(lambda row: Point(row['Near End Lon'], row['Near End Lat']), axis = 1)\n",
    "xx['p4'] = xx.apply(lambda row: Point(row['Far End Lon'], row['Far End Lat']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create the polygon need to make a list of each of the points, for each row\n",
    "#pl = [xx['p2'][0], xx['p1'][0], xx['p3'][0], xx['p4'][0]]\n",
    "xx['pl'] = xx.apply(lambda row: [row['p2'], row['p1'], row['p3'], row['p4']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a polygon from each list of corner points\n",
    "xx['geometry'] = xx.apply(lambda row: Polygon([p.x, p.y] for p in row['pl']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the polygon to a shapefile\n",
    "\n",
    "# Define a polygon feature geometry with one attribute\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'id': 'int'},\n",
    "}\n",
    "\n",
    "# Write a new Shapefile\n",
    "for num, val in enumerate(xx['geometry']):\n",
    "    with fiona.open(xx['Granule Name'][num]+'.shp', 'w', 'ESRI Shapefile', schema) as c:\n",
    "        ## If there are multiple geometries, put the \"for\" loop here\n",
    "        c.write({\n",
    "            'geometry': mapping(val),\n",
    "            'properties': {'id': 123},\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-72.43337606712592 2.589096336565627 0.6359289927846135 0.6237292379226238\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,5.801921911053878)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.01271857985569227\" opacity=\"0.6\" d=\"M -72.40982314146723,3.0865096150706868 L -71.92127757113815,3.1892726488295615 L -71.821,2.716 L -72.31149243583707,2.6126492622243163 L -72.40982314146723,3.0865096150706868 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x294aba876c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use geodataframe to find intersection\n",
    "gdf = gpd.GeoDataFrame(xx, geometry=xx['geometry'])\n",
    "inters = reduce(Polygon.intersection, gdf.geometry)\n",
    "inters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the polygon to a shapefile\n",
    "\n",
    "# Define a polygon feature geometry with one attribute\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {'id': 'int'},\n",
    "}\n",
    "\n",
    "# Write a new Shapefile\n",
    "with fiona.open('intersect.shp', 'w', crs=from_epsg(4326), driver='ESRI Shapefile', schema=schema) as c:\n",
    "    ## If there are multiple geometries, put the \"for\" loop here\n",
    "    c.write({\n",
    "        'geometry': mapping(inters),\n",
    "        'properties': {'id': 123},\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
